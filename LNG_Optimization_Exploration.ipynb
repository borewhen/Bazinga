{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70da243c",
   "metadata": {},
   "source": [
    "\n",
    "# LNG Optimisation â€” Exploration Notebook (Clean & Runnable)\n",
    "\n",
    "This notebook gives you a **single, endâ€‘toâ€‘end workflow**:\n",
    "1. Load **real market data** (robust Excel parsing, JKM-friendly).\n",
    "2. Build a **unit-economics & riskâ€‘aware profit table** per destination.\n",
    "3. Solve an **allocation LP** with PuLP to maximise (riskâ€‘adjusted) profit under capacity & supply constraints.\n",
    "4. Run **scenarios** and visualise allocations and P&L.\n",
    "\n",
    "> **Note:** Charts are rendered with matplotlib only (no seaborn), and each chart is on its own figure as requested.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb72511",
   "metadata": {},
   "source": [
    "## 0) Setup & Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f51498",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If PuLP is not installed, uncomment:\n",
    "# %pip install pulp openpyxl --quiet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pulp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cffa99",
   "metadata": {},
   "source": [
    "## 1) Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c801bae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class LoaderConfig:\n",
    "    data_folder: Path = Path(\"data\")\n",
    "    # Explicitly use the first sheet by default to avoid dict-of-DFs from pandas:\n",
    "    sheet: Optional[str | int] = 0\n",
    "    excel_engine: Optional[str] = \"openpyxl\"\n",
    "\n",
    "    historical_files: Dict[str, str] = field(default_factory=lambda: {\n",
    "        \"jkm_historical\": \"JKM Spot LNG Historical (Extracted 23Sep25).xlsx\",\n",
    "        \"henry_hub_historical\": \"Henry Hub Historical (Extracted 23Sep25).xlsx\",\n",
    "        \"ttf_historical\": \"TTF Historical (Extracted 23Sep25).xlsx\",\n",
    "    })\n",
    "\n",
    "    forward_files: Dict[str, str] = field(default_factory=lambda: {\n",
    "        \"jkm_forward\": \"JKM Spot LNG Forward (Extracted 23Sep25).xlsx\",\n",
    "        \"henry_hub_forward\": \"Henry Hub Forward (Extracted 23Sep25).xlsx\",\n",
    "        \"ttf_forward\": \"TTF Forward (Extracted 23Sep25).xlsx\",\n",
    "    })\n",
    "\n",
    "cfg = LoaderConfig()\n",
    "print('Looking for data in:', cfg.data_folder.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2818c6ac",
   "metadata": {},
   "source": [
    "## 2) Robust Excel Loader (JKM-friendly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0504c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "class LNGLoader:\n",
    "    def __init__(self, cfg: LoaderConfig):\n",
    "        self.cfg = cfg\n",
    "        self.historical_data: Dict[str, pd.DataFrame] = {}\n",
    "        self.forward_data: Dict[str, pd.DataFrame] = {}\n",
    "        self.metrics: Dict[str, Dict] = {}\n",
    "\n",
    "    # ---- IO helpers ----\n",
    "    def _read_sheet(self, path: Path, header=None) -> pd.DataFrame:\n",
    "        df = pd.read_excel(path, sheet_name=self.cfg.sheet, engine=self.cfg.excel_engine, header=header)\n",
    "        if isinstance(df, dict):  # safety\n",
    "            key = list(df.keys())[0]\n",
    "            df = df[key]\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def _clean_str(x) -> str:\n",
    "        if x is None or (isinstance(x, float) and np.isnan(x)): return \"\"\n",
    "        return str(x).strip().replace(\"\\xa0\",\" \").lower()\n",
    "\n",
    "    def _find_row_containing(self, df: pd.DataFrame, patterns: Iterable[str], anywhere: bool = False) -> Optional[int]:\n",
    "        pats = [re.compile(p, flags=re.I) for p in patterns]\n",
    "        for i in range(len(df)):\n",
    "            row = df.iloc[i]\n",
    "            cells = row.tolist() if anywhere else [row.iloc[0]]\n",
    "            text = \" \".join(self._clean_str(c) for c in cells)\n",
    "            if any(p.search(text) for p in pats):\n",
    "                return i\n",
    "        return None\n",
    "\n",
    "    def _find_header_row(self, df: pd.DataFrame, start: int, window: int, contains: List[str]) -> Optional[int]:\n",
    "        wants = [self._clean_str(x) for x in contains]\n",
    "        for i in range(start, min(start+window, len(df))):\n",
    "            row_text = \" \".join(self._clean_str(x) for x in df.iloc[i].tolist())\n",
    "            if all(tok in row_text for tok in wants):\n",
    "                return i\n",
    "        return None\n",
    "\n",
    "    def _find_table_end(self, df: pd.DataFrame, start: int, stop_keywords: List[str]) -> int:\n",
    "        stops = [self._clean_str(k) for k in stop_keywords]\n",
    "        for i in range(start, len(df)):\n",
    "            first = self._clean_str(df.iloc[i].iloc[0])\n",
    "            if first == \"\" or any(k in first for k in stops):\n",
    "                return i\n",
    "        return len(df)\n",
    "\n",
    "    # ---- Cleaners ----\n",
    "    def _clean_generic_price(self, df: pd.DataFrame, source_name: str) -> pd.DataFrame:\n",
    "        df2 = df.copy()\n",
    "        df2.replace(r\"^\\s*$\", np.nan, regex=True, inplace=True)\n",
    "        df2.dropna(how=\"all\", inplace=True)\n",
    "        df2.columns = [f\"col{j}\" for j in range(df2.shape[1])]\n",
    "\n",
    "        # Attempt to find date & price columns by name; fallback to first two\n",
    "        dcol = next((c for c in df2.columns if re.search(r\"date|exchange\", str(c), re.I)), df2.columns[0])\n",
    "        pcol = next((c for c in df2.columns if re.search(r\"close|price|settle|usd\", str(c), re.I)), df2.columns[1])\n",
    "\n",
    "        out = df2[[dcol, pcol]].rename(columns={dcol:\"date\", pcol:\"price\"})\n",
    "        out[\"date\"] = pd.to_datetime(out[\"date\"], errors=\"coerce\")\n",
    "        out[\"price\"] = pd.to_numeric(out[\"price\"], errors=\"coerce\")\n",
    "        out.dropna(subset=[\"date\",\"price\"], inplace=True)\n",
    "        out.sort_values(\"date\", inplace=True)\n",
    "        out.set_index(\"date\", inplace=True)\n",
    "        out[\"daily_return\"] = out[\"price\"].pct_change()\n",
    "        out[\"volatility_30d\"] = out[\"daily_return\"].rolling(30).std() * np.sqrt(252)\n",
    "        out[\"source\"] = source_name\n",
    "        return out\n",
    "\n",
    "    def _clean_jkm(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        # 1) find \"JKMc1 History\" anchor anywhere in the row\n",
    "        anchor = self._find_row_containing(df, [r\"jkmc?1\\s+history\"], anywhere=True)\n",
    "        if anchor is None:\n",
    "            return self._clean_generic_price(df, \"jkm_historical\")\n",
    "\n",
    "        # 2) find header within next rows (must contain both terms)\n",
    "        header = self._find_header_row(df, start=anchor, window=25, contains=[\"exchange date\", \"close\"])\n",
    "        if header is None:\n",
    "            return self._clean_generic_price(df, \"jkm_historical\")\n",
    "\n",
    "        # 3) slice until blank/new section\n",
    "        end = self._find_table_end(df, start=header+1, stop_keywords=[\"statistics\",\"vap\",\"summary\"])\n",
    "        body = df.iloc[header+1:end].copy()\n",
    "        cols = [self._clean_str(x) or f\"col{j}\" for j,x in enumerate(df.iloc[header].tolist())]\n",
    "        body.columns = cols\n",
    "\n",
    "        # map columns\n",
    "        dcol = next((c for c in body.columns if \"exchange date\" in c or \"date\" in c), None)\n",
    "        pcol = next((c for c in body.columns if \"close\" in c or \"price\" in c or \"settle\" in c), None)\n",
    "        if dcol is None or pcol is None:\n",
    "            return self._clean_generic_price(df, \"jkm_historical\")\n",
    "\n",
    "        out = body[[dcol,pcol]].rename(columns={dcol:\"date\", pcol:\"price\"})\n",
    "        out[\"date\"] = pd.to_datetime(out[\"date\"], errors=\"coerce\")\n",
    "        out[\"price\"] = pd.to_numeric(out[\"price\"], errors=\"coerce\")\n",
    "        out.dropna(subset=[\"date\",\"price\"], inplace=True)\n",
    "        out.sort_values(\"date\", inplace=True)\n",
    "        out.set_index(\"date\", inplace=True)\n",
    "        out[\"daily_return\"] = out[\"price\"].pct_change()\n",
    "        out[\"volatility_30d\"] = out[\"daily_return\"].rolling(30).std() * np.sqrt(252)\n",
    "        out[\"source\"] = \"jkm_historical\"\n",
    "        return out\n",
    "\n",
    "    # ---- Public load ----\n",
    "    def load_all(self) -> None:\n",
    "        print(\"ðŸ“ˆ Loading historical price data...\")\n",
    "        for key, fname in cfg.historical_files.items():\n",
    "            fpath = cfg.data_folder / fname\n",
    "            print(f\"  â€¢ {key}: {fpath.name}\")\n",
    "            if not fpath.exists():\n",
    "                print(\"    â†³ âš ï¸ Not found; skipping.\")\n",
    "                continue\n",
    "            try:\n",
    "                df_raw = self._read_sheet(fpath, header=None)\n",
    "                df_clean = self._clean_jkm(df_raw) if \"jkm\" in key.lower() else self._clean_generic_price(df_raw, key)\n",
    "                if df_clean.empty:\n",
    "                    print(\"    â†³ âŒ No rows after cleaning.\")\n",
    "                else:\n",
    "                    self.historical_data[key] = df_clean\n",
    "                    print(f\"    â†³ âœ… {len(df_clean)} rows.\")\n",
    "            except Exception as e:\n",
    "                print(f\"    â†³ âŒ Error: {e}\")\n",
    "\n",
    "        print(\"ðŸ“ˆ Loading forward curve data...\")\n",
    "        for key, fname in cfg.forward_files.items():\n",
    "            fpath = cfg.data_folder / fname\n",
    "            print(f\"  â€¢ {key}: {fpath.name}\")\n",
    "            if not fpath.exists():\n",
    "                print(\"    â†³ âš ï¸ Not found; skipping.\")\n",
    "                continue\n",
    "            try:\n",
    "                df_raw = self._read_sheet(fpath, header=0)\n",
    "                df_raw.replace(r\"^\\s*$\", np.nan, regex=True, inplace=True)\n",
    "                df_raw.dropna(how=\"all\", inplace=True)\n",
    "                self.forward_data[key] = df_raw\n",
    "                print(f\"    â†³ âœ… {len(df_raw)} rows.\")\n",
    "            except Exception as e:\n",
    "                print(f\"    â†³ âŒ Error: {e}\")\n",
    "\n",
    "    def latest_prices(self) -> Dict[str, float]:\n",
    "        out = {}\n",
    "        for name, df in self.historical_data.items():\n",
    "            if df.empty: \n",
    "                continue\n",
    "            latest = float(df[\"price\"].iloc[-1])\n",
    "            n = name.lower()\n",
    "            if \"jkm\" in n: out[\"JP\"] = latest\n",
    "            elif \"ttf\" in n: out[\"SLNG\"] = latest * 1.1\n",
    "            elif \"henry_hub\" in n: out[\"CN\"] = latest * 1.5\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bae7a9",
   "metadata": {},
   "source": [
    "## 3) Sample Ports & Assumptions (fallback if no files found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38159155",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If you already have the CSV/JSON from the Streamlit scaffold, you can reuse those.\n",
    "# Otherwise, we'll define small inline defaults so the notebook runs anywhere.\n",
    "\n",
    "ports_df = pd.DataFrame([\n",
    "    {\"name\":\"Singapore\",\"code\":\"SLNG\",\"distance_nm\":600,\"monthly_capacity_cargo\":10,\"handling_fee_per_unit\":0.25},\n",
    "    {\"name\":\"Japan (JKM)\",\"code\":\"JP\",\"distance_nm\":1800,\"monthly_capacity_cargo\":12,\"handling_fee_per_unit\":0.30},\n",
    "    {\"name\":\"China\",\"code\":\"CN\",\"distance_nm\":1500,\"monthly_capacity_cargo\":9,\"handling_fee_per_unit\":0.28},\n",
    "])\n",
    "\n",
    "assumptions = {\n",
    "    \"supply_cargo_units\": 20,\n",
    "    \"boiloff_rate_per_1000nm\": 0.0015,\n",
    "    \"freight_cost_per_nm_per_unit\": 0.02,\n",
    "    \"variable_cost_per_unit\": 5.0,\n",
    "    \"carbon_cost_per_unit\": 0.0,\n",
    "}\n",
    "\n",
    "# If loader pulls real prices, those will override this map.\n",
    "fallback_prices = {\"SLNG\": 12.0, \"JP\": 14.0, \"CN\": 11.0}\n",
    "\n",
    "ports_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa9e63e",
   "metadata": {},
   "source": [
    "## 4) Unit Economics + LP Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e7daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def delivered_fraction(distance_nm: float, boiloff_rate_per_1000nm: float) -> float:\n",
    "    loss = (distance_nm/1000.0) * boiloff_rate_per_1000nm\n",
    "    return max(0.0, 1.0 - loss)\n",
    "\n",
    "def unit_profit(price_per_unit, distance_nm, handling_fee, a):\n",
    "    delivered = delivered_fraction(distance_nm, a[\"boiloff_rate_per_1000nm\"])\n",
    "    revenue = price_per_unit * delivered\n",
    "    freight = a[\"freight_cost_per_nm_per_unit\"] * distance_nm\n",
    "    costs = a[\"variable_cost_per_unit\"] + handling_fee + freight + a.get(\"carbon_cost_per_unit\",0.0)\n",
    "    return revenue - costs, delivered\n",
    "\n",
    "def build_profit_table(ports_df: pd.DataFrame, price_map: Dict[str, float], a: dict) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for _, r in ports_df.iterrows():\n",
    "        code = r[\"code\"]\n",
    "        price = price_map.get(code, np.nan)\n",
    "        up, delivered = unit_profit(price, r[\"distance_nm\"], r[\"handling_fee_per_unit\"], a)\n",
    "        rows.append({\n",
    "            \"code\": code,\n",
    "            \"name\": r[\"name\"],\n",
    "            \"distance_nm\": r[\"distance_nm\"],\n",
    "            \"monthly_capacity_cargo\": r[\"monthly_capacity_cargo\"],\n",
    "            \"price_per_unit\": price,\n",
    "            \"unit_profit\": up,\n",
    "            \"delivered_fraction\": delivered\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def optimise_allocation(unit_tbl: pd.DataFrame, total_supply_units: float) -> Dict:\n",
    "    codes = unit_tbl[\"code\"].tolist()\n",
    "    profit = {row[\"code\"]: float(row[\"unit_profit\"]) for _, row in unit_tbl.iterrows()}\n",
    "    capacity = {row[\"code\"]: float(row[\"monthly_capacity_cargo\"]) for _, row in unit_tbl.iterrows()}\n",
    "    m = pulp.LpProblem(\"lng_allocation\", pulp.LpMaximize)\n",
    "    x = pulp.LpVariable.dicts(\"alloc\", codes, lowBound=0)\n",
    "    # objective\n",
    "    m += pulp.lpSum([profit[c]*x[c] for c in codes])\n",
    "    # constraints\n",
    "    m += pulp.lpSum([x[c] for c in codes]) <= float(total_supply_units), \"Supply\"\n",
    "    for c in codes:\n",
    "        m += x[c] <= capacity[c], f\"Cap_{c}\"\n",
    "    m.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "    alloc = {c: float(x[c].value() or 0.0) for c in codes}\n",
    "    return {\"allocation\": alloc, \"objective\": float(pulp.value(m.objective))}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89292335",
   "metadata": {},
   "source": [
    "## 5) Load Market Files (if present) and Build Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e591a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = LNGLoader(cfg)\n",
    "loader.load_all()\n",
    "\n",
    "price_map = fallback_prices.copy()\n",
    "price_map.update(loader.latest_prices())  # real prices override\n",
    "\n",
    "unit_tbl = build_profit_table(ports_df, price_map, assumptions)\n",
    "unit_tbl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f125fa",
   "metadata": {},
   "source": [
    "## 6) Solve and Visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e318362",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res = optimise_allocation(unit_tbl, assumptions[\"supply_cargo_units\"])\n",
    "alloc = pd.DataFrame([{\"code\":k, \"allocation\":v} for k,v in res[\"allocation\"].items()]).merge(\n",
    "    unit_tbl[[\"code\",\"name\",\"unit_profit\",\"delivered_fraction\"]], on=\"code\"\n",
    ").sort_values(\"allocation\", ascending=False)\n",
    "\n",
    "print(\"Expected Profit (objective): ${:,.0f}\".format(res[\"objective\"]))\n",
    "\n",
    "# Plot: Allocation\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(alloc[\"name\"], alloc[\"allocation\"])\n",
    "plt.title(\"Optimal Allocation (cargo units)\")\n",
    "plt.xlabel(\"Destination\")\n",
    "plt.ylabel(\"Units\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot: Unit profit\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(unit_tbl[\"name\"], unit_tbl[\"unit_profit\"])\n",
    "plt.title(\"Unit Profit by Destination (USD / loaded unit)\")\n",
    "plt.xlabel(\"Destination\")\n",
    "plt.ylabel(\"Unit Profit\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "alloc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e48479",
   "metadata": {},
   "source": [
    "## 7) Scenario Analysis (Cold Snap, SLNG Outage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71207723",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_scenario(name: str, price_shocks=None, capacity_mult=None):\n",
    "    price_shocks = price_shocks or {}\n",
    "    capacity_mult = capacity_mult or {}\n",
    "\n",
    "    pm = price_map.copy()\n",
    "    for k,v in price_shocks.items():\n",
    "        if k in pm:\n",
    "            pm[k] += v\n",
    "\n",
    "    pf = ports_df.copy()\n",
    "    pf[\"monthly_capacity_cargo\"] = pf.apply(lambda r: r[\"monthly_capacity_cargo\"] * capacity_mult.get(r[\"code\"],1.0), axis=1)\n",
    "\n",
    "    tbl = build_profit_table(pf, pm, assumptions)\n",
    "    res = optimise_allocation(tbl, assumptions[\"supply_cargo_units\"])\n",
    "\n",
    "    delivered = sum(tbl.set_index(\"code\").loc[c, \"delivered_fraction\"] * x for c,x in res[\"allocation\"].items())\n",
    "    return name, res[\"objective\"], res[\"allocation\"], tbl, delivered\n",
    "\n",
    "scenarios = [\n",
    "    (\"Base\", {}, {}),\n",
    "    (\"Cold snap NE Asia\", {\"JP\": 3.0, \"CN\": 1.5}, {}),\n",
    "    (\"SLNG outage\", {}, {\"SLNG\": 0.5}),\n",
    "]\n",
    "\n",
    "rows = []\n",
    "scenario_tables = {}\n",
    "for name, shocks, caps in scenarios:\n",
    "    nm, obj, alloc_map, tbl, delivered = run_scenario(name, shocks, caps)\n",
    "    scenario_tables[name] = (alloc_map, tbl)\n",
    "    rows.append({\"scenario\": nm, \"profit\": obj, \"delivered_units\": delivered})\n",
    "\n",
    "sc_df = pd.DataFrame(rows)\n",
    "sc_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad020fa",
   "metadata": {},
   "source": [
    "### Scenario Profit Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8411993",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(sc_df[\"scenario\"], sc_df[\"profit\"])\n",
    "plt.title(\"Scenario Comparison â€” Profit\")\n",
    "plt.xlabel(\"Scenario\")\n",
    "plt.ylabel(\"Profit (USD)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4491ef",
   "metadata": {},
   "source": [
    "## 8) Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd87132",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Price map used:\", price_map)\n",
    "print(\"\\nTop-line:\")\n",
    "for _, r in sc_df.iterrows():\n",
    "    print(f\"  {r['scenario']}: profit=${r['profit']:,.0f}, deliveredâ‰ˆ{r['delivered_units']:.2f} units\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
