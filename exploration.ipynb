{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f428e5bf",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae5bc7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pulp\n",
      "  Downloading pulp-3.3.0-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading pulp-3.3.0-py3-none-any.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pulp\n",
      "Successfully installed pulp-3.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pulp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc2c892f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš¢ Enhanced LNG Trade Strategy Optimization\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Enhanced LNG Trade Strategy Optimization\n",
    "# P&L factoring in demand/supply, market prices, and counterparty risks\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from typing import Dict, List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dataclasses import dataclass\n",
    "from scipy.stats import norm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"ðŸš¢ Enhanced LNG Trade Strategy Optimization\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e51529e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Risk management and demand/supply models defined\n"
     ]
    }
   ],
   "source": [
    "# 1. Enhanced Data Models and Risk Management Classes\n",
    "\n",
    "@dataclass\n",
    "class CounterpartyRisk:\n",
    "    \"\"\"Counterparty risk profile\"\"\"\n",
    "    code: str\n",
    "    name: str\n",
    "    credit_rating: str\n",
    "    credit_limit: float\n",
    "    default_probability: float\n",
    "    country_risk: float = 0.0\n",
    "\n",
    "@dataclass\n",
    "class MarketProfile:\n",
    "    \"\"\"Market demand/supply profile\"\"\"\n",
    "    code: str\n",
    "    name: str\n",
    "    base_demand: float\n",
    "    demand_elasticity: float\n",
    "    seasonal_factors: Dict[str, float]\n",
    "    volatility: float\n",
    "    supply_disruption_risk: float\n",
    "\n",
    "class CounterpartyRiskManager:\n",
    "    \"\"\"Manages counterparty credit risk and exposure limits\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.counterparties = {}\n",
    "        self.exposure_limits = {}\n",
    "    \n",
    "    def add_counterparty(self, risk_profile: CounterpartyRisk):\n",
    "        \"\"\"Add a counterparty risk profile\"\"\"\n",
    "        self.counterparties[risk_profile.code] = risk_profile\n",
    "        self.exposure_limits[risk_profile.code] = risk_profile.credit_limit\n",
    "    \n",
    "    def get_risk_adjustment(self, counterparty_code: str, exposure: float) -> float:\n",
    "        \"\"\"Calculate risk adjustment based on counterparty credit quality and exposure\"\"\"\n",
    "        if counterparty_code not in self.counterparties:\n",
    "            return 0.0\n",
    "        \n",
    "        counterparty = self.counterparties[counterparty_code]\n",
    "        \n",
    "        # Base risk from credit rating\n",
    "        rating_risk = self._rating_to_risk(counterparty.credit_rating)\n",
    "        \n",
    "        # Exposure concentration risk\n",
    "        credit_limit = self.exposure_limits[counterparty_code]\n",
    "        utilization = exposure / credit_limit if credit_limit > 0 else 0\n",
    "        concentration_risk = max(0, (utilization - 0.7) * 0.2)  # Penalty above 70% utilization\n",
    "        \n",
    "        # Country risk\n",
    "        country_risk = counterparty.country_risk\n",
    "        \n",
    "        return rating_risk + concentration_risk + country_risk\n",
    "    \n",
    "    def _rating_to_risk(self, rating: str) -> float:\n",
    "        \"\"\"Convert credit rating to risk adjustment factor\"\"\"\n",
    "        rating_map = {\n",
    "            'AAA': 0.001, 'AA+': 0.002, 'AA': 0.003, 'AA-': 0.004,\n",
    "            'A+': 0.005, 'A': 0.007, 'A-': 0.010,\n",
    "            'BBB+': 0.015, 'BBB': 0.020, 'BBB-': 0.030,\n",
    "            'BB+': 0.040, 'BB': 0.060, 'BB-': 0.080,\n",
    "            'B+': 0.100, 'B': 0.150, 'B-': 0.200,\n",
    "            'CCC': 0.300, 'CC': 0.500, 'C': 0.800\n",
    "        }\n",
    "        return rating_map.get(rating, 0.100)  # Default to high risk\n",
    "\n",
    "class DemandSupplyModel:\n",
    "    \"\"\"Models demand/supply dynamics and market behavior\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.markets = {}\n",
    "        self.base_prices = {}\n",
    "    \n",
    "    def add_market(self, market_profile: MarketProfile, base_price: float):\n",
    "        \"\"\"Add a market profile with base price\"\"\"\n",
    "        self.markets[market_profile.code] = market_profile\n",
    "        self.base_prices[market_profile.code] = base_price\n",
    "    \n",
    "    def calculate_effective_demand(self, market_code: str, price: float, \n",
    "                                 season: str = \"normal\") -> float:\n",
    "        \"\"\"Calculate effective demand considering price elasticity and seasonality\"\"\"\n",
    "        if market_code not in self.markets:\n",
    "            return 0.0\n",
    "        \n",
    "        market = self.markets[market_code]\n",
    "        base_price = self.base_prices[market_code]\n",
    "        \n",
    "        # Price elasticity effect\n",
    "        price_ratio = price / base_price\n",
    "        elasticity = market.demand_elasticity\n",
    "        price_effect = price_ratio ** elasticity\n",
    "        \n",
    "        # Seasonal effect\n",
    "        seasonal_factor = market.seasonal_factors.get(season, 1.0)\n",
    "        \n",
    "        # Supply disruption risk\n",
    "        disruption_factor = 1 - market.supply_disruption_risk\n",
    "        \n",
    "        return market.base_demand * price_effect * seasonal_factor * disruption_factor\n",
    "    \n",
    "    def calculate_price_volatility_impact(self, market_code: str, confidence_level: float = 0.95) -> float:\n",
    "        \"\"\"Calculate Value-at-Risk impact from price volatility\"\"\"\n",
    "        if market_code not in self.markets:\n",
    "            return 0.0\n",
    "        \n",
    "        volatility = self.markets[market_code].volatility\n",
    "        z_score = norm.ppf(1 - confidence_level)\n",
    "        return z_score * volatility\n",
    "\n",
    "print(\"âœ… Risk management and demand/supply models defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3d58f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Enhanced financial calculations defined\n"
     ]
    }
   ],
   "source": [
    "# 2. Enhanced Financial Calculations\n",
    "\n",
    "def calculate_enhanced_unit_profit(\n",
    "    price_per_unit: float,\n",
    "    distance_nm: float,\n",
    "    handling_fee_per_unit: float,\n",
    "    boiloff_rate_per_1000nm: float,\n",
    "    freight_cost_per_nm_per_unit: float,\n",
    "    variable_cost_per_unit: float,\n",
    "    carbon_cost_per_unit: float = 0.0,\n",
    "    counterparty_risk_adjustment: float = 0.0,\n",
    "    market_volatility_impact: float = 0.0\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Enhanced unit profit calculation with risk adjustments\n",
    "    Returns detailed breakdown of profit components\n",
    "    \"\"\"\n",
    "    # Basic calculations\n",
    "    delivered_frac = max(0.0, 1.0 - (distance_nm / 1000.0) * boiloff_rate_per_1000nm)\n",
    "    revenue = price_per_unit * delivered_frac\n",
    "    \n",
    "    # Cost components\n",
    "    freight = freight_cost_per_nm_per_unit * distance_nm\n",
    "    total_costs = variable_cost_per_unit + handling_fee_per_unit + freight + carbon_cost_per_unit\n",
    "    \n",
    "    # Base profit\n",
    "    base_profit = revenue - total_costs\n",
    "    \n",
    "    # Risk adjustments\n",
    "    counterparty_risk_cost = base_profit * counterparty_risk_adjustment\n",
    "    volatility_cost = abs(base_profit) * market_volatility_impact\n",
    "    \n",
    "    # Risk-adjusted profit\n",
    "    risk_adjusted_profit = base_profit - counterparty_risk_cost - volatility_cost\n",
    "    \n",
    "    return {\n",
    "        'base_profit': base_profit,\n",
    "        'risk_adjusted_profit': risk_adjusted_profit,\n",
    "        'revenue': revenue,\n",
    "        'total_costs': total_costs,\n",
    "        'delivered_fraction': delivered_frac,\n",
    "        'counterparty_risk_cost': counterparty_risk_cost,\n",
    "        'volatility_cost': volatility_cost,\n",
    "        'net_margin': risk_adjusted_profit / revenue if revenue > 0 else 0\n",
    "    }\n",
    "\n",
    "def build_enhanced_profit_table(\n",
    "    ports_df: pd.DataFrame, \n",
    "    price_map: Dict[str, float],\n",
    "    assumptions: Dict[str, float],\n",
    "    risk_manager: CounterpartyRiskManager,\n",
    "    demand_model: DemandSupplyModel\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Build comprehensive profit table with risk adjustments\"\"\"\n",
    "    \n",
    "    rows = []\n",
    "    for _, port in ports_df.iterrows():\n",
    "        code = port[\"code\"]\n",
    "        price = price_map.get(code, np.nan)\n",
    "        \n",
    "        if np.isnan(price):\n",
    "            continue\n",
    "            \n",
    "        # Calculate risk adjustments\n",
    "        counterparty_risk = risk_manager.get_risk_adjustment(code, 0)  # Initial exposure = 0\n",
    "        volatility_impact = demand_model.calculate_price_volatility_impact(code)\n",
    "        \n",
    "        # Calculate enhanced unit profit\n",
    "        profit_components = calculate_enhanced_unit_profit(\n",
    "            price_per_unit=price,\n",
    "            distance_nm=float(port[\"distance_nm\"]),\n",
    "            handling_fee_per_unit=float(port[\"handling_fee_per_unit\"]),\n",
    "            boiloff_rate_per_1000nm=float(assumptions[\"boiloff_rate_per_1000nm\"]),\n",
    "            freight_cost_per_nm_per_unit=float(assumptions[\"freight_cost_per_nm_per_unit\"]),\n",
    "            variable_cost_per_unit=float(assumptions[\"variable_cost_per_unit\"]),\n",
    "            carbon_cost_per_unit=float(assumptions.get(\"carbon_cost_per_unit\", 0.0)),\n",
    "            counterparty_risk_adjustment=counterparty_risk,\n",
    "            market_volatility_impact=volatility_impact\n",
    "        )\n",
    "        \n",
    "        # Calculate effective demand\n",
    "        effective_demand = demand_model.calculate_effective_demand(code, price)\n",
    "        \n",
    "        # Calculate risk-adjusted capacity (considering counterparty limits)\n",
    "        credit_limit = risk_manager.exposure_limits.get(code, float('inf'))\n",
    "        risk_adjusted_capacity = min(\n",
    "            float(port[\"monthly_capacity_cargo\"]),\n",
    "            credit_limit,\n",
    "            effective_demand\n",
    "        )\n",
    "        \n",
    "        rows.append({\n",
    "            \"code\": code,\n",
    "            \"name\": port[\"name\"],\n",
    "            \"distance_nm\": port[\"distance_nm\"],\n",
    "            \"monthly_capacity_cargo\": port[\"monthly_capacity_cargo\"],\n",
    "            \"risk_adjusted_capacity\": risk_adjusted_capacity,\n",
    "            \"price_per_unit\": price,\n",
    "            \"effective_demand\": effective_demand,\n",
    "            \"base_profit\": profit_components['base_profit'],\n",
    "            \"risk_adjusted_profit\": profit_components['risk_adjusted_profit'],\n",
    "            \"delivered_fraction\": profit_components['delivered_fraction'],\n",
    "            \"counterparty_risk\": counterparty_risk,\n",
    "            \"volatility_impact\": volatility_impact,\n",
    "            \"net_margin\": profit_components['net_margin'],\n",
    "            \"credit_limit\": credit_limit\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "print(\"âœ… Enhanced financial calculations defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5edb36d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Enhanced optimization with risk constraints defined\n"
     ]
    }
   ],
   "source": [
    "# 3. Enhanced Optimization with Risk Constraints\n",
    "\n",
    "import pulp\n",
    "\n",
    "def optimize_with_risk_constraints(\n",
    "    profit_table: pd.DataFrame,\n",
    "    total_supply_units: float,\n",
    "    risk_manager: CounterpartyRiskManager,\n",
    "    max_portfolio_risk: float = 0.15,\n",
    "    diversification_factor: float = 0.3\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Enhanced optimization considering multiple risk constraints\n",
    "    \"\"\"\n",
    "    codes = profit_table[\"code\"].tolist()\n",
    "    \n",
    "    # Create optimization problem\n",
    "    m = pulp.LpProblem(\"lng_allocation_enhanced\", pulp.LpMaximize)\n",
    "    x = pulp.LpVariable.dicts(\"alloc\", codes, lowBound=0)\n",
    "    \n",
    "    # Objective: maximize risk-adjusted profit\n",
    "    risk_adjusted_profit = {row[\"code\"]: float(row[\"risk_adjusted_profit\"]) for _, row in profit_table.iterrows()}\n",
    "    m += pulp.lpSum([risk_adjusted_profit[c] * x[c] for c in codes])\n",
    "    \n",
    "    # Supply constraint\n",
    "    m += pulp.lpSum([x[c] for c in codes]) <= float(total_supply_units), \"SupplyLimit\"\n",
    "    \n",
    "    # Individual capacity constraints\n",
    "    for _, row in profit_table.iterrows():\n",
    "        code = row[\"code\"]\n",
    "        capacity = float(row[\"risk_adjusted_capacity\"])\n",
    "        m += x[code] <= capacity, f\"Capacity_{code}\"\n",
    "    \n",
    "    # Credit limit constraints\n",
    "    for code in codes:\n",
    "        credit_limit = risk_manager.exposure_limits.get(code, float('inf'))\n",
    "        if credit_limit < float('inf'):\n",
    "            m += x[code] <= credit_limit, f\"CreditLimit_{code}\"\n",
    "    \n",
    "    # Portfolio diversification constraint (no single counterparty > 50% of supply)\n",
    "    max_single_allocation = total_supply_units * (1 - diversification_factor)\n",
    "    for code in codes:\n",
    "        m += x[code] <= max_single_allocation, f\"Diversification_{code}\"\n",
    "    \n",
    "    # Solve optimization\n",
    "    m.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "    \n",
    "    # Extract results\n",
    "    allocation = {c: float(x[c].value() or 0.0) for c in codes}\n",
    "    objective = pulp.value(m.objective)\n",
    "    \n",
    "    # Calculate risk metrics\n",
    "    total_exposure = sum(allocation.values())\n",
    "    risk_metrics = calculate_portfolio_risk_metrics(allocation, profit_table, risk_manager)\n",
    "    \n",
    "    return {\n",
    "        \"allocation\": allocation,\n",
    "        \"objective\": objective,\n",
    "        \"total_exposure\": total_exposure,\n",
    "        \"risk_metrics\": risk_metrics,\n",
    "        \"optimization_status\": pulp.LpStatus[m.status]\n",
    "    }\n",
    "\n",
    "def calculate_portfolio_risk_metrics(\n",
    "    allocation: Dict[str, float],\n",
    "    profit_table: pd.DataFrame,\n",
    "    risk_manager: CounterpartyRiskManager\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Calculate comprehensive portfolio risk metrics\"\"\"\n",
    "    \n",
    "    # Concentration risk (Herfindahl index)\n",
    "    total_allocation = sum(allocation.values())\n",
    "    if total_allocation > 0:\n",
    "        herfindahl = sum((allocation[code] / total_allocation) ** 2 for code in allocation.keys())\n",
    "    else:\n",
    "        herfindahl = 0.0\n",
    "    \n",
    "    # Average counterparty risk\n",
    "    weighted_risk = 0.0\n",
    "    for code, amount in allocation.items():\n",
    "        if amount > 0:\n",
    "            risk = risk_manager.get_risk_adjustment(code, amount)\n",
    "            weighted_risk += risk * amount\n",
    "    \n",
    "    avg_counterparty_risk = weighted_risk / total_allocation if total_allocation > 0 else 0.0\n",
    "    \n",
    "    # Credit utilization\n",
    "    max_utilization = 0.0\n",
    "    for code, amount in allocation.items():\n",
    "        if amount > 0:\n",
    "            credit_limit = risk_manager.exposure_limits.get(code, float('inf'))\n",
    "            if credit_limit < float('inf'):\n",
    "                utilization = amount / credit_limit\n",
    "                max_utilization = max(max_utilization, utilization)\n",
    "    \n",
    "    return {\n",
    "        \"herfindahl_index\": herfindahl,\n",
    "        \"avg_counterparty_risk\": avg_counterparty_risk,\n",
    "        \"max_credit_utilization\": max_utilization,\n",
    "        \"diversification_score\": 1 - herfindahl,  # Higher is better\n",
    "        \"risk_score\": (herfindahl + avg_counterparty_risk + max_utilization) / 3\n",
    "    }\n",
    "\n",
    "print(\"âœ… Enhanced optimization with risk constraints defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b69b945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Enhanced optimization with risk constraints defined\n"
     ]
    }
   ],
   "source": [
    "# 3. Enhanced Optimization with Risk Constraints\n",
    "\n",
    "import pulp\n",
    "\n",
    "def optimize_with_risk_constraints(\n",
    "    profit_table: pd.DataFrame,\n",
    "    total_supply_units: float,\n",
    "    risk_manager: CounterpartyRiskManager,\n",
    "    max_portfolio_risk: float = 0.15,\n",
    "    diversification_factor: float = 0.3\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Enhanced optimization considering multiple risk constraints\n",
    "    \"\"\"\n",
    "    codes = profit_table[\"code\"].tolist()\n",
    "    \n",
    "    # Create optimization problem\n",
    "    m = pulp.LpProblem(\"lng_allocation_enhanced\", pulp.LpMaximize)\n",
    "    x = pulp.LpVariable.dicts(\"alloc\", codes, lowBound=0)\n",
    "    \n",
    "    # Objective: maximize risk-adjusted profit\n",
    "    risk_adjusted_profit = {row[\"code\"]: float(row[\"risk_adjusted_profit\"]) for _, row in profit_table.iterrows()}\n",
    "    m += pulp.lpSum([risk_adjusted_profit[c] * x[c] for c in codes])\n",
    "    \n",
    "    # Supply constraint\n",
    "    m += pulp.lpSum([x[c] for c in codes]) <= float(total_supply_units), \"SupplyLimit\"\n",
    "    \n",
    "    # Individual capacity constraints\n",
    "    for _, row in profit_table.iterrows():\n",
    "        code = row[\"code\"]\n",
    "        capacity = float(row[\"risk_adjusted_capacity\"])\n",
    "        m += x[code] <= capacity, f\"Capacity_{code}\"\n",
    "    \n",
    "    # Credit limit constraints\n",
    "    for code in codes:\n",
    "        credit_limit = risk_manager.exposure_limits.get(code, float('inf'))\n",
    "        if credit_limit < float('inf'):\n",
    "            m += x[code] <= credit_limit, f\"CreditLimit_{code}\"\n",
    "    \n",
    "    # Portfolio diversification constraint (no single counterparty > 50% of supply)\n",
    "    max_single_allocation = total_supply_units * (1 - diversification_factor)\n",
    "    for code in codes:\n",
    "        m += x[code] <= max_single_allocation, f\"Diversification_{code}\"\n",
    "    \n",
    "    # Solve optimization\n",
    "    m.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "    \n",
    "    # Extract results\n",
    "    allocation = {c: float(x[c].value() or 0.0) for c in codes}\n",
    "    objective = pulp.value(m.objective)\n",
    "    \n",
    "    # Calculate risk metrics\n",
    "    total_exposure = sum(allocation.values())\n",
    "    risk_metrics = calculate_portfolio_risk_metrics(allocation, profit_table, risk_manager)\n",
    "    \n",
    "    return {\n",
    "        \"allocation\": allocation,\n",
    "        \"objective\": objective,\n",
    "        \"total_exposure\": total_exposure,\n",
    "        \"risk_metrics\": risk_metrics,\n",
    "        \"optimization_status\": pulp.LpStatus[m.status]\n",
    "    }\n",
    "\n",
    "def calculate_portfolio_risk_metrics(\n",
    "    allocation: Dict[str, float],\n",
    "    profit_table: pd.DataFrame,\n",
    "    risk_manager: CounterpartyRiskManager\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Calculate comprehensive portfolio risk metrics\"\"\"\n",
    "    \n",
    "    # Concentration risk (Herfindahl index)\n",
    "    total_allocation = sum(allocation.values())\n",
    "    if total_allocation > 0:\n",
    "        herfindahl = sum((allocation[code] / total_allocation) ** 2 for code in allocation.keys())\n",
    "    else:\n",
    "        herfindahl = 0.0\n",
    "    \n",
    "    # Average counterparty risk\n",
    "    weighted_risk = 0.0\n",
    "    for code, amount in allocation.items():\n",
    "        if amount > 0:\n",
    "            risk = risk_manager.get_risk_adjustment(code, amount)\n",
    "            weighted_risk += risk * amount\n",
    "    \n",
    "    avg_counterparty_risk = weighted_risk / total_allocation if total_allocation > 0 else 0.0\n",
    "    \n",
    "    # Credit utilization\n",
    "    max_utilization = 0.0\n",
    "    for code, amount in allocation.items():\n",
    "        if amount > 0:\n",
    "            credit_limit = risk_manager.exposure_limits.get(code, float('inf'))\n",
    "            if credit_limit < float('inf'):\n",
    "                utilization = amount / credit_limit\n",
    "                max_utilization = max(max_utilization, utilization)\n",
    "    \n",
    "    return {\n",
    "        \"herfindahl_index\": herfindahl,\n",
    "        \"avg_counterparty_risk\": avg_counterparty_risk,\n",
    "        \"max_credit_utilization\": max_utilization,\n",
    "        \"diversification_score\": 1 - herfindahl,  # Higher is better\n",
    "        \"risk_score\": (herfindahl + avg_counterparty_risk + max_utilization) / 3\n",
    "    }\n",
    "\n",
    "print(\"âœ… Enhanced optimization with risk constraints defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ce8edd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Data loaded successfully\n",
      "Ports: 3 destinations\n",
      "Base supply: 20 units\n"
     ]
    }
   ],
   "source": [
    "# 4. Load and Setup Data\n",
    "\n",
    "# Load existing data\n",
    "ports_df = pd.read_csv(\"data/ports.csv\")\n",
    "with open(\"data/base_inputs.json\") as f:\n",
    "    base_inputs = json.load(f)\n",
    "\n",
    "# Enhanced assumptions\n",
    "enhanced_assumptions = {\n",
    "    **base_inputs[\"assumptions\"],\n",
    "    \"risk_tolerance\": 0.15,\n",
    "    \"diversification_target\": 0.3,\n",
    "    \"confidence_level\": 0.95\n",
    "}\n",
    "\n",
    "# Enhanced price data with volatility\n",
    "enhanced_prices = {\n",
    "    **base_inputs[\"prices_usd_per_unit\"],\n",
    "    \"SLNG\": 12.0,  # Singapore\n",
    "    \"JP\": 14.0,    # Japan\n",
    "    \"CN\": 11.0     # China\n",
    "}\n",
    "\n",
    "print(\"ðŸ“Š Data loaded successfully\")\n",
    "print(f\"Ports: {len(ports_df)} destinations\")\n",
    "print(f\"Base supply: {enhanced_assumptions['supply_cargo_units']} units\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3601338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Risk management and market models initialized\n",
      "Counterparties: 3\n",
      "Markets: 3\n"
     ]
    }
   ],
   "source": [
    "# 5. Setup Risk Management and Market Models\n",
    "\n",
    "# Initialize risk manager\n",
    "risk_manager = CounterpartyRiskManager()\n",
    "\n",
    "# Add counterparty risk profiles\n",
    "counterparties = [\n",
    "    CounterpartyRisk(\"SLNG\", \"Singapore LNG\", \"AA\", 50.0, 0.002, 0.02),\n",
    "    CounterpartyRisk(\"JP\", \"Japan (JKM)\", \"AAA\", 100.0, 0.001, 0.01),\n",
    "    CounterpartyRisk(\"CN\", \"China\", \"A\", 30.0, 0.005, 0.05)\n",
    "]\n",
    "\n",
    "for cp in counterparties:\n",
    "    risk_manager.add_counterparty(cp)\n",
    "\n",
    "# Initialize demand/supply model\n",
    "demand_model = DemandSupplyModel()\n",
    "\n",
    "# Add market profiles\n",
    "markets = [\n",
    "    MarketProfile(\"SLNG\", \"Singapore LNG\", 15.0, -0.3, \n",
    "                 {\"winter\": 1.2, \"summer\": 0.8, \"normal\": 1.0}, 0.15, 0.02),\n",
    "    MarketProfile(\"JP\", \"Japan (JKM)\", 20.0, -0.4,\n",
    "                 {\"winter\": 1.5, \"summer\": 0.7, \"normal\": 1.0}, 0.20, 0.01),\n",
    "    MarketProfile(\"CN\", \"China\", 18.0, -0.6,\n",
    "                 {\"winter\": 1.3, \"summer\": 0.9, \"normal\": 1.0}, 0.25, 0.05)\n",
    "]\n",
    "\n",
    "for market in markets:\n",
    "    base_price = enhanced_prices[market.code]\n",
    "    demand_model.add_market(market, base_price)\n",
    "\n",
    "print(\"âœ… Risk management and market models initialized\")\n",
    "print(f\"Counterparties: {len(risk_manager.counterparties)}\")\n",
    "print(f\"Markets: {len(demand_model.markets)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc2ebfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ˆ Enhanced Profit Analysis\n",
      "==================================================\n",
      "          name  base_profit  risk_adjusted_profit  counterparty_risk  \\\n",
      "0    Singapore       -5.261                -3.842              0.023   \n",
      "1  Japan (JKM)      -27.338               -18.044              0.011   \n",
      "2        China      -24.305               -12.925              0.057   \n",
      "\n",
      "   volatility_impact  net_margin  effective_demand  \n",
      "0             -0.247      -0.320              14.7  \n",
      "1             -0.329      -1.292              19.8  \n",
      "2             -0.411      -1.178              17.1  \n"
     ]
    }
   ],
   "source": [
    "# 6. Build Enhanced Profit Table\n",
    "\n",
    "# Build comprehensive profit table\n",
    "profit_table = build_enhanced_profit_table(\n",
    "    ports_df, \n",
    "    enhanced_prices, \n",
    "    enhanced_assumptions,\n",
    "    risk_manager, \n",
    "    demand_model\n",
    ")\n",
    "\n",
    "print(\"ðŸ“ˆ Enhanced Profit Analysis\")\n",
    "print(\"=\" * 50)\n",
    "print(profit_table[['name', 'base_profit', 'risk_adjusted_profit', 'counterparty_risk', \n",
    "                   'volatility_impact', 'net_margin', 'effective_demand']].round(3))\n",
    "\n",
    "# Visualize profit components\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Base vs Risk-adjusted profit\n",
    "axes[0,0].bar(profit_table['name'], profit_table['base_profit'], \n",
    "              alpha=0.7, label='Base Profit', color='lightblue')\n",
    "axes[0,0].bar(profit_table['name'], profit_table['risk_adjusted_profit'], \n",
    "              alpha=0.7, label='Risk-adjusted Profit', color='darkblue')\n",
    "axes[0,0].set_title('Base vs Risk-adjusted Profit')\n",
    "axes[0,0].set_ylabel('Profit per Unit ($)')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Risk components\n",
    "axes[0,1].bar(profit_table['name'], profit_table['counterparty_risk'], \n",
    "              alpha=0.7, label='Counterparty Risk', color='red')\n",
    "axes[0,1].bar(profit_table['name'], profit_table['volatility_impact'], \n",
    "              alpha=0.7, label='Volatility Impact', color='orange')\n",
    "axes[0,1].set_title('Risk Components')\n",
    "axes[0,1].set_ylabel('Risk Adjustment Factor')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Net margins\n",
    "axes[1,0].bar(profit_table['name'], profit_table['net_margin'], \n",
    "              color='green', alpha=0.7)\n",
    "axes[1,0].set_title('Net Margins')\n",
    "axes[1,0].set_ylabel('Net Margin (%)')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Effective demand vs capacity\n",
    "axes[1,1].bar(profit_table['name'], profit_table['monthly_capacity_cargo'], \n",
    "              alpha=0.5, label='Capacity', color='lightgray')\n",
    "axes[1,1].bar(profit_table['name'], profit_table['effective_demand'], \n",
    "              alpha=0.7, label='Effective Demand', color='purple')\n",
    "axes[1,1].set_title('Capacity vs Effective Demand')\n",
    "axes[1,1].set_ylabel('Units')\n",
    "axes[1,1].legend()\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b6b97a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugging Optimization Constraints\n",
      "==================================================\n",
      "Destinations with positive risk-adjusted profit: 0\n",
      "No destinations have positive risk-adjusted profit!\n",
      "Risk adjustments may be too high. Consider:\n",
      "  â€¢ Reducing counterparty risk factors\n",
      "  â€¢ Lowering volatility impact\n",
      "  â€¢ Adjusting credit ratings\n",
      "\n",
      "Total risk-adjusted capacity: 31.00\n",
      "Supply to allocate: 20\n",
      "Capacity sufficient: Yes\n",
      "\n",
      "Credit limits:\n",
      "  SLNG: 50.0\n",
      "  JP: 100.0\n",
      "  CN: 30.0\n",
      "\n",
      "Max single allocation (diversification): 14.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Debugging Optimization Constraints\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check if any destinations have positive risk-adjusted profit\n",
    "profitable_destinations = profit_table[profit_table['risk_adjusted_profit'] > 0]\n",
    "print(f\"Destinations with positive risk-adjusted profit: {len(profitable_destinations)}\")\n",
    "if len(profitable_destinations) > 0:\n",
    "    print(profitable_destinations[['name', 'risk_adjusted_profit', 'risk_adjusted_capacity']].round(3))\n",
    "else:\n",
    "    print(\"No destinations have positive risk-adjusted profit!\")\n",
    "    print(\"Risk adjustments may be too high. Consider:\")\n",
    "    print(\"  â€¢ Reducing counterparty risk factors\")\n",
    "    print(\"  â€¢ Lowering volatility impact\")\n",
    "    print(\"  â€¢ Adjusting credit ratings\")\n",
    "\n",
    "# Check capacity constraints\n",
    "total_capacity = profit_table['risk_adjusted_capacity'].sum()\n",
    "print(f\"\\nTotal risk-adjusted capacity: {total_capacity:.2f}\")\n",
    "print(f\"Supply to allocate: {supply_units}\")\n",
    "print(f\"Capacity sufficient: {'Yes' if total_capacity >= supply_units else 'No'}\")\n",
    "\n",
    "# Check credit limits\n",
    "print(f\"\\nCredit limits:\")\n",
    "for code in profit_table['code']:\n",
    "    limit = risk_manager.exposure_limits.get(code, float('inf'))\n",
    "    print(f\"  {code}: {limit if limit < float('inf') else 'No limit'}\")\n",
    "\n",
    "# Check diversification constraint\n",
    "max_single_allocation = supply_units * (1 - enhanced_assumptions['diversification_target'])\n",
    "print(f\"\\nMax single allocation (diversification): {max_single_allocation:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e8dd1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified optimization function - replace the complex one if needed\n",
    "\n",
    "def simple_optimize_with_risks(\n",
    "    profit_table: pd.DataFrame,\n",
    "    total_supply_units: float,\n",
    "    risk_manager: CounterpartyRiskManager\n",
    ") -> Dict:\n",
    "    \"\"\"Simplified optimization with basic risk constraints\"\"\"\n",
    "    \n",
    "    codes = profit_table[\"code\"].tolist()\n",
    "    \n",
    "    # Create optimization problem\n",
    "    m = pulp.LpProblem(\"lng_allocation_simple\", pulp.LpMaximize)\n",
    "    x = pulp.LpVariable.dicts(\"alloc\", codes, lowBound=0)\n",
    "    \n",
    "    # Objective: maximize risk-adjusted profit\n",
    "    risk_adjusted_profit = {row[\"code\"]: float(row[\"risk_adjusted_profit\"]) for _, row in profit_table.iterrows()}\n",
    "    m += pulp.lpSum([risk_adjusted_profit[c] * x[c] for c in codes])\n",
    "    \n",
    "    # Supply constraint\n",
    "    m += pulp.lpSum([x[c] for c in codes]) <= float(total_supply_units), \"SupplyLimit\"\n",
    "    \n",
    "    # Individual capacity constraints (use original capacity, not risk-adjusted)\n",
    "    for _, row in profit_table.iterrows():\n",
    "        code = row[\"code\"]\n",
    "        capacity = float(row[\"monthly_capacity_cargo\"])\n",
    "        m += x[code] <= capacity, f\"Capacity_{code}\"\n",
    "    \n",
    "    # Credit limit constraints (only if reasonable)\n",
    "    for code in codes:\n",
    "        credit_limit = risk_manager.exposure_limits.get(code, float('inf'))\n",
    "        if credit_limit < float('inf') and credit_limit > supply_units * 0.1:  # Only apply if limit is reasonable\n",
    "            m += x[code] <= credit_limit, f\"CreditLimit_{code}\"\n",
    "    \n",
    "    # Solve optimization\n",
    "    m.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "    \n",
    "    # Extract results\n",
    "    allocation = {c: float(x[c].value() or 0.0) for c in codes}\n",
    "    objective = pulp.value(m.objective)\n",
    "    \n",
    "    # Calculate basic risk metrics\n",
    "    total_exposure = sum(allocation.values())\n",
    "    \n",
    "    return {\n",
    "        \"allocation\": allocation,\n",
    "        \"objective\": objective,\n",
    "        \"total_exposure\": total_exposure,\n",
    "        \"optimization_status\": pulp.LpStatus[m.status]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b38571b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒ¡ï¸ Scenario Analysis Results\n",
      "==================================================\n",
      "                  Scenario  Total Profit  Total Allocation  Risk Score  \\\n",
      "0                Base Case           0.0               0.0         0.0   \n",
      "1        Cold Snap NE Asia           0.0               0.0         0.0   \n",
      "2              SLNG Outage           0.0               0.0         0.0   \n",
      "3       China Demand Surge           0.0               0.0         0.0   \n",
      "4  Global Price Volatility           0.0               0.0         0.0   \n",
      "\n",
      "   Diversification  \n",
      "0              1.0  \n",
      "1              1.0  \n",
      "2              1.0  \n",
      "3              1.0  \n",
      "4              1.0  \n"
     ]
    }
   ],
   "source": [
    "# 8. Scenario Analysis\n",
    "\n",
    "def run_scenario_analysis(scenario_name: str, price_shocks: Dict[str, float], \n",
    "                         capacity_multipliers: Dict[str, float] = None) -> Dict:\n",
    "    \"\"\"Run optimization under different scenarios\"\"\"\n",
    "    \n",
    "    # Apply price shocks\n",
    "    scenario_prices = enhanced_prices.copy()\n",
    "    for market, shock in price_shocks.items():\n",
    "        scenario_prices[market] = scenario_prices.get(market, 0) + shock\n",
    "    \n",
    "    # Apply capacity multipliers\n",
    "    scenario_ports = ports_df.copy()\n",
    "    if capacity_multipliers:\n",
    "        scenario_ports['monthly_capacity_cargo'] = scenario_ports.apply(\n",
    "            lambda r: r['monthly_capacity_cargo'] * capacity_multipliers.get(r['code'], 1.0), \n",
    "            axis=1\n",
    "        )\n",
    "    \n",
    "    # Build profit table for scenario\n",
    "    scenario_profit_table = build_enhanced_profit_table(\n",
    "        scenario_ports, \n",
    "        scenario_prices, \n",
    "        enhanced_assumptions,\n",
    "        risk_manager, \n",
    "        demand_model\n",
    "    )\n",
    "    \n",
    "    # Run optimization\n",
    "    scenario_result = optimize_with_risk_constraints(\n",
    "        scenario_profit_table,\n",
    "        supply_units,\n",
    "        risk_manager,\n",
    "        max_portfolio_risk=enhanced_assumptions['risk_tolerance'],\n",
    "        diversification_factor=enhanced_assumptions['diversification_target']\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'scenario_name': scenario_name,\n",
    "        'prices': scenario_prices,\n",
    "        'profit_table': scenario_profit_table,\n",
    "        'optimization_result': scenario_result\n",
    "    }\n",
    "\n",
    "# Define scenarios\n",
    "scenarios = {\n",
    "    'Base Case': ({}, {}),\n",
    "    'Cold Snap NE Asia': ({'JP': 3.0, 'CN': 1.5}, {}),\n",
    "    'SLNG Outage': ({}, {'SLNG': 0.5}),\n",
    "    'China Demand Surge': ({'CN': 2.0}, {'CN': 1.5}),\n",
    "    'Global Price Volatility': ({'SLNG': 1.0, 'JP': 2.0, 'CN': 1.5}, {})\n",
    "}\n",
    "\n",
    "# Run scenario analysis\n",
    "scenario_results = {}\n",
    "for name, (price_shocks, capacity_multipliers) in scenarios.items():\n",
    "    result = run_scenario_analysis(name, price_shocks, capacity_multipliers)\n",
    "    scenario_results[name] = result\n",
    "\n",
    "print(\"ðŸŒ¡ï¸ Scenario Analysis Results\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Compare scenarios\n",
    "scenario_comparison = []\n",
    "for name, result in scenario_results.items():\n",
    "    opt_result = result['optimization_result']\n",
    "    scenario_comparison.append({\n",
    "        'Scenario': name,\n",
    "        'Total Profit': opt_result['objective'],\n",
    "        'Total Allocation': opt_result['total_exposure'],\n",
    "        'Risk Score': opt_result['risk_metrics']['risk_score'],\n",
    "        'Diversification': opt_result['risk_metrics']['diversification_score']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(scenario_comparison)\n",
    "print(comparison_df.round(3))\n",
    "\n",
    "# Visualize scenario comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Profit comparison\n",
    "axes[0,0].bar(comparison_df['Scenario'], comparison_df['Total Profit'], \n",
    "              color='lightblue', alpha=0.7)\n",
    "axes[0,0].set_title('Total Profit by Scenario')\n",
    "axes[0,0].set_ylabel('Profit ($)')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Risk comparison\n",
    "axes[0,1].bar(comparison_df['Scenario'], comparison_df['Risk Score'], \n",
    "              color='red', alpha=0.7)\n",
    "axes[0,1].set_title('Risk Score by Scenario')\n",
    "axes[0,1].set_ylabel('Risk Score')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Diversification comparison\n",
    "axes[1,0].bar(comparison_df['Scenario'], comparison_df['Diversification'], \n",
    "              color='green', alpha=0.7)\n",
    "axes[1,0].set_title('Diversification Score by Scenario')\n",
    "axes[1,0].set_ylabel('Diversification Score')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Allocation comparison\n",
    "allocation_comparison = []\n",
    "for name, result in scenario_results.items():\n",
    "    allocation = result['optimization_result']['allocation']\n",
    "    for code, amount in allocation.items():\n",
    "        if amount > 0:\n",
    "            allocation_comparison.append({\n",
    "                'Scenario': name,\n",
    "                'Destination': profit_table[profit_table['code'] == code]['name'].iloc[0],\n",
    "                'Allocation': amount\n",
    "            })\n",
    "\n",
    "if allocation_comparison:\n",
    "    allocation_df = pd.DataFrame(allocation_comparison)\n",
    "    pivot_df = allocation_df.pivot(index='Scenario', columns='Destination', values='Allocation').fillna(0)\n",
    "    pivot_df.plot(kind='bar', ax=axes[1,1], stacked=True)\n",
    "    axes[1,1].set_title('Allocation by Scenario')\n",
    "    axes[1,1].set_ylabel('Allocation (units)')\n",
    "    axes[1,1].tick_params(axis='x', rotation=45)\n",
    "    axes[1,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "758a229c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Sensitivity Analysis Results\n",
      "==================================================\n",
      "\n",
      "Freight Cost Sensitivity:\n",
      "  Profit Range: $0.00 - $9.05\n",
      "  Profit Volatility: $2.86\n",
      "\n",
      "Boiloff Rate Sensitivity:\n",
      "  Profit Range: $0.00 - $0.00\n",
      "  Profit Volatility: $0.00\n",
      "\n",
      "Risk Tolerance Sensitivity:\n",
      "  Profit Range: $0.00 - $0.00\n",
      "  Profit Volatility: $0.00\n"
     ]
    }
   ],
   "source": [
    "# 9. Sensitivity Analysis\n",
    "\n",
    "def sensitivity_analysis(parameter: str, values: List[float], \n",
    "                        base_value: float) -> pd.DataFrame:\n",
    "    \"\"\"Run sensitivity analysis on key parameters\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    original_value = enhanced_assumptions.get(parameter, base_value)\n",
    "    \n",
    "    for value in values:\n",
    "        # Update assumptions\n",
    "        test_assumptions = enhanced_assumptions.copy()\n",
    "        test_assumptions[parameter] = value\n",
    "        \n",
    "        # Build profit table\n",
    "        test_profit_table = build_enhanced_profit_table(\n",
    "            ports_df, \n",
    "            enhanced_prices, \n",
    "            test_assumptions,\n",
    "            risk_manager, \n",
    "            demand_model\n",
    "        )\n",
    "        \n",
    "        # Run optimization\n",
    "        test_result = optimize_with_risk_constraints(\n",
    "            test_profit_table,\n",
    "            supply_units,\n",
    "            risk_manager,\n",
    "            max_portfolio_risk=enhanced_assumptions['risk_tolerance'],\n",
    "            diversification_factor=enhanced_assumptions['diversification_target']\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'parameter': parameter,\n",
    "            'value': value,\n",
    "            'total_profit': test_result['objective'],\n",
    "            'total_allocation': test_result['total_exposure'],\n",
    "            'risk_score': test_result['risk_metrics']['risk_score']\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run sensitivity analysis on key parameters\n",
    "sensitivity_results = {}\n",
    "\n",
    "# Freight cost sensitivity\n",
    "freight_values = np.linspace(0.01, 0.05, 10)\n",
    "sensitivity_results['freight_cost'] = sensitivity_analysis(\n",
    "    'freight_cost_per_nm_per_unit', freight_values, 0.02\n",
    ")\n",
    "\n",
    "# Boil-off rate sensitivity\n",
    "boiloff_values = np.linspace(0.001, 0.003, 10)\n",
    "sensitivity_results['boiloff_rate'] = sensitivity_analysis(\n",
    "    'boiloff_rate_per_1000nm', boiloff_values, 0.0015\n",
    ")\n",
    "\n",
    "# Risk tolerance sensitivity\n",
    "risk_values = np.linspace(0.05, 0.25, 10)\n",
    "sensitivity_results['risk_tolerance'] = sensitivity_analysis(\n",
    "    'risk_tolerance', risk_values, 0.15\n",
    ")\n",
    "\n",
    "print(\"ðŸ“Š Sensitivity Analysis Results\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Visualize sensitivity analysis\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Freight cost sensitivity\n",
    "axes[0].plot(sensitivity_results['freight_cost']['value'], \n",
    "             sensitivity_results['freight_cost']['total_profit'], 'o-')\n",
    "axes[0].set_title('Freight Cost Sensitivity')\n",
    "axes[0].set_xlabel('Freight Cost ($/nm/unit)')\n",
    "axes[0].set_ylabel('Total Profit ($)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Boil-off rate sensitivity\n",
    "axes[1].plot(sensitivity_results['boiloff_rate']['value'], \n",
    "             sensitivity_results['boiloff_rate']['total_profit'], 'o-', color='orange')\n",
    "axes[1].set_title('Boil-off Rate Sensitivity')\n",
    "axes[1].set_xlabel('Boil-off Rate (per 1000nm)')\n",
    "axes[1].set_ylabel('Total Profit ($)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Risk tolerance sensitivity\n",
    "axes[2].plot(sensitivity_results['risk_tolerance']['value'], \n",
    "             sensitivity_results['risk_tolerance']['total_profit'], 'o-', color='green')\n",
    "axes[2].set_title('Risk Tolerance Sensitivity')\n",
    "axes[2].set_xlabel('Risk Tolerance')\n",
    "axes[2].set_ylabel('Total Profit ($)')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display sensitivity summary\n",
    "for param, results in sensitivity_results.items():\n",
    "    print(f\"\\n{param.replace('_', ' ').title()} Sensitivity:\")\n",
    "    print(f\"  Profit Range: ${results['total_profit'].min():.2f} - ${results['total_profit'].max():.2f}\")\n",
    "    print(f\"  Profit Volatility: ${results['total_profit'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4417d4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ LNG Trade Strategy Optimization Summary\n",
      "============================================================\n",
      "\n",
      "ðŸ“ˆ Base Case Performance:\n",
      "  Total Expected Profit: $0.00\n",
      "  Total Allocation: 0.00 units\n",
      "  Risk Score: 0.000\n",
      "  Diversification Score: 1.000\n",
      "\n",
      "ðŸŽ¯ Key Insights:\n",
      "  â€¢ Risk-adjusted optimization reduces profit by ~100.0% but improves risk profile\n",
      "  â€¢ Portfolio is 100.0% diversified\n",
      "  â€¢ Highest risk-adjusted profit destination: Singapore\n",
      "  â€¢ Most constrained by credit limits: CN\n",
      "\n",
      "ðŸ’¡ Recommendations:\n",
      "  1. Monitor counterparty credit quality and adjust limits accordingly\n",
      "  2. Consider hedging strategies for high-volatility markets\n",
      "  3. Implement dynamic pricing based on demand elasticity\n",
      "  4. Regular stress testing under various scenarios\n",
      "  5. Portfolio rebalancing based on risk metrics\n",
      "\n",
      "ðŸ”§ Next Steps:\n",
      "  â€¢ Integrate real-time market data feeds\n",
      "  â€¢ Add more sophisticated risk models (VaR, CVaR)\n",
      "  â€¢ Implement multi-period optimization\n",
      "  â€¢ Add storage and inventory management\n",
      "  â€¢ Develop automated rebalancing triggers\n",
      "\n",
      "âœ… Enhanced LNG Trade Strategy Optimization Complete!\n"
     ]
    }
   ],
   "source": [
    "# 10. Summary and Recommendations\n",
    "\n",
    "print(\"LNG Trade Strategy Optimization Summary\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Base case results\n",
    "base_result = scenario_results['Base Case']['optimization_result']\n",
    "print(f\"\\nBase Case Performance:\")\n",
    "print(f\"  Total Expected Profit: ${base_result['objective']:,.2f}\")\n",
    "print(f\"  Total Allocation: {base_result['total_exposure']:.2f} units\")\n",
    "print(f\"  Risk Score: {base_result['risk_metrics']['risk_score']:.3f}\")\n",
    "print(f\"  Diversification Score: {base_result['risk_metrics']['diversification_score']:.3f}\")\n",
    "\n",
    "print(f\"\\nKey Insights:\")\n",
    "print(f\"  â€¢ Risk-adjusted optimization reduces profit by ~{((profit_table['base_profit'].sum() - base_result['objective']) / profit_table['base_profit'].sum() * 100):.1f}% but improves risk profile\")\n",
    "print(f\"  â€¢ Portfolio is {base_result['risk_metrics']['diversification_score']:.1%} diversified\")\n",
    "print(f\"  â€¢ Highest risk-adjusted profit destination: {profit_table.loc[profit_table['risk_adjusted_profit'].idxmax(), 'name']}\")\n",
    "print(f\"  â€¢ Most constrained by credit limits: {min(risk_manager.exposure_limits.items(), key=lambda x: x[1])[0]}\")\n",
    "\n",
    "print(f\"\\nRecommendations:\")\n",
    "print(f\"  1. Monitor counterparty credit quality and adjust limits accordingly\")\n",
    "print(f\"  2. Consider hedging strategies for high-volatility markets\")\n",
    "print(f\"  3. Implement dynamic pricing based on demand elasticity\")\n",
    "print(f\"  4. Regular stress testing under various scenarios\")\n",
    "print(f\"  5. Portfolio rebalancing based on risk metrics\")\n",
    "\n",
    "print(f\"\\nNext Steps:\")\n",
    "print(f\"  â€¢ Integrate real-time market data feeds\")\n",
    "print(f\"  â€¢ Add more sophisticated risk models (VaR, CVaR)\")\n",
    "print(f\"  â€¢ Implement multi-period optimization\")\n",
    "print(f\"  â€¢ Add storage and inventory management\")\n",
    "print(f\"  â€¢ Develop automated rebalancing triggers\")\n",
    "\n",
    "print(\"\\nEnhanced LNG Trade Strategy Optimization Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c9a075",
   "metadata": {},
   "source": [
    "# Data Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d54e1d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Loading Real LNG Market Data from: data\n",
      "======================================================================\n",
      "ðŸ“ˆ Loading historical price data...\n",
      "  â€¢ jkm_historical: JKM Spot LNG Historical (Extracted 23Sep25).xlsx\n",
      "    â†³ âœ… 753 rows.\n",
      "  â€¢ henry_hub_historical: Henry Hub Historical (Extracted 23Sep25).xlsx\n",
      "    â†³ âœ… 753 rows.\n",
      "  â€¢ ttf_historical: TTF Historical (Extracted 23Sep25).xlsx\n",
      "    â†³ âœ… 760 rows.\n",
      "  â€¢ brent_historical: Brent Oil Historical Prices (Extracted 01Oct25).xlsx\n",
      "    â†³ âœ… 461 rows.\n",
      "  â€¢ wti_historical: WTI Historical (Extracted 23Sep25).xlsx\n",
      "    â†³ âœ… 503 rows.\n",
      "ðŸ“ˆ Loading forward curve data...\n",
      "  â€¢ jkm_forward: JKM Spot LNG Forward (Extracted 23Sep25).xlsx\n",
      "    â†³ âœ… 62 rows.\n",
      "  â€¢ henry_hub_forward: Henry Hub Forward (Extracted 23Sep25).xlsx\n",
      "    â†³ âœ… 15 rows.\n",
      "  â€¢ ttf_forward: TTF Forward (Extracted 23Sep25).xlsx\n",
      "    â†³ âœ… 23 rows.\n",
      "  â€¢ wti_forward: WTI Forward (Extracted 23Sep25).xlsx\n",
      "    â†³ âœ… 124 rows.\n",
      "\n",
      "ðŸ“Š Market Data Summary\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "jkm_historical:\n",
      "  current_price: 11.2700\n",
      "  price_change_30d: -5.4927\n",
      "  volatility_30d: 0.2722\n",
      "  price_52w_high: 42.4700\n",
      "  price_52w_low: 8.1250\n",
      "  data_points: 753\n",
      "  date_range: 2022-09-23 to 2025-09-23\n",
      "\n",
      "henry_hub_historical:\n",
      "  current_price: 2.7980\n",
      "  price_change_30d: -0.3561\n",
      "  volatility_30d: 0.4160\n",
      "  price_52w_high: 7.3080\n",
      "  price_52w_low: 1.5750\n",
      "  data_points: 753\n",
      "  date_range: 2022-09-23 to 2025-09-23\n",
      "\n",
      "ttf_historical:\n",
      "  current_price: 31.9500\n",
      "  price_change_30d: 0.9479\n",
      "  volatility_30d: 0.2871\n",
      "  price_52w_high: 207.8000\n",
      "  price_52w_low: 21.0000\n",
      "  data_points: 760\n",
      "  date_range: 2022-09-23 to 2025-09-22\n",
      "\n",
      "brent_historical:\n",
      "  current_price: 67.9600\n",
      "  price_change_30d: -19.7070\n",
      "  volatility_30d: 0.9512\n",
      "  price_52w_high: 132.7200\n",
      "  price_52w_low: 9.8200\n",
      "  data_points: 461\n",
      "  date_range: 1987-05-15 to 2025-09-15\n",
      "\n",
      "wti_historical:\n",
      "  current_price: 65.2600\n",
      "  price_change_30d: 4.1660\n",
      "  volatility_30d: 0.2485\n",
      "  price_52w_high: 93.6800\n",
      "  price_52w_low: 57.1300\n",
      "  data_points: 503\n",
      "  date_range: 2023-09-25 to 2025-09-29\n",
      "\n",
      "ðŸ’° Current Prices for Optimisation mapping\n",
      "  JP: 11.27\n",
      "  CN: 4.20\n",
      "  SLNG: 35.15\n"
     ]
    }
   ],
   "source": [
    "# lng_loader.py\n",
    "# Clean LNG Market Data Loader â€” robust, modular, and JKM-friendly\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "import warnings\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# ------------------------------- Config ------------------------------------ #\n",
    "\n",
    "@dataclass\n",
    "class LoaderConfig:\n",
    "    data_folder: Path = Path(\"data\")\n",
    "\n",
    "    # File names (you can swap these to patterns if you like)\n",
    "    historical_files: Dict[str, str] = field(default_factory=lambda: {\n",
    "        \"jkm_historical\": \"JKM Spot LNG Historical (Extracted 23Sep25).xlsx\",\n",
    "        \"henry_hub_historical\": \"Henry Hub Historical (Extracted 23Sep25).xlsx\",\n",
    "        \"ttf_historical\": \"TTF Historical (Extracted 23Sep25).xlsx\",\n",
    "        \"brent_historical\": \"Brent Oil Historical Prices (Extracted 01Oct25).xlsx\",\n",
    "        \"wti_historical\": \"WTI Historical (Extracted 23Sep25).xlsx\",\n",
    "    })\n",
    "    forward_files: Dict[str, str] = field(default_factory=lambda: {\n",
    "        \"jkm_forward\": \"JKM Spot LNG Forward (Extracted 23Sep25).xlsx\",\n",
    "        \"henry_hub_forward\": \"Henry Hub Forward (Extracted 23Sep25).xlsx\",\n",
    "        \"ttf_forward\": \"TTF Forward (Extracted 23Sep25).xlsx\",\n",
    "        \"wti_forward\": \"WTI Forward (Extracted 23Sep25).xlsx\",\n",
    "    })\n",
    "\n",
    "    # Parsing\n",
    "    excel_engine: Optional[str] = \"openpyxl\"\n",
    "    sheet: Optional[str | int] = 0  # autodetect first sheet if None\n",
    "\n",
    "    # Cleaning\n",
    "    boiloff_window_days: int = 30  # used for volatility calc (rolling window)\n",
    "    annualization_trading_days: int = 252\n",
    "\n",
    "\n",
    "# ----------------------------- Loader Class -------------------------------- #\n",
    "\n",
    "class LNGDataLoader:\n",
    "    \"\"\"\n",
    "    Clean and organized LNG market data loader with robust Excel parsing,\n",
    "    especially for JKM \"Price History\" workbooks that have multi-section sheets.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: LoaderConfig | None = None):\n",
    "        self.cfg = config or LoaderConfig()\n",
    "        self.historical_data: Dict[str, pd.DataFrame] = {}\n",
    "        self.forward_data: Dict[str, pd.DataFrame] = {}\n",
    "        self.market_metrics: Dict[str, Dict] = {}\n",
    "\n",
    "    # ----------------------------- Public API ------------------------------ #\n",
    "\n",
    "    def load_all_data(self) -> Dict[str, pd.DataFrame]:\n",
    "        print(\"ðŸ“Š Loading Real LNG Market Data from:\", self.cfg.data_folder)\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "        self._load_historical_data()\n",
    "        self._load_forward_data()\n",
    "        self.market_metrics = self._calculate_market_metrics()\n",
    "        return self.historical_data\n",
    "\n",
    "    def get_current_prices_for_optimization(self) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Map latest prices to the optimiserâ€™s destination codes.\n",
    "        Adjust mapping logic to your use-case.\n",
    "        \"\"\"\n",
    "        current: Dict[str, float] = {}\n",
    "        for name, df in self.historical_data.items():\n",
    "            if df.empty or \"price\" not in df.columns:\n",
    "                continue\n",
    "            latest = float(df[\"price\"].iloc[-1])\n",
    "            n = name.lower()\n",
    "            if \"jkm\" in n:\n",
    "                current[\"JP\"] = latest\n",
    "            elif \"henry_hub\" in n:\n",
    "                # Example uplift to reflect liquefaction + voyage; calibrate with your basis model.\n",
    "                current[\"CN\"] = latest * 1.5\n",
    "            elif \"ttf\" in n:\n",
    "                current[\"SLNG\"] = latest * 1.1\n",
    "        return current\n",
    "\n",
    "    def export_data(self, filename: str = \"lng_market_data.xlsx\") -> None:\n",
    "        if not self.historical_data and not self.forward_data:\n",
    "            print(\"âŒ Nothing to export.\")\n",
    "            return\n",
    "        try:\n",
    "            with pd.ExcelWriter(filename, engine=\"openpyxl\") as writer:\n",
    "                for name, df in self.historical_data.items():\n",
    "                    if not df.empty:\n",
    "                        df.to_excel(writer, sheet_name=f\"{name}_historical\")\n",
    "                for name, df in self.forward_data.items():\n",
    "                    if not df.empty:\n",
    "                        df.to_excel(writer, sheet_name=f\"{name}_forward\")\n",
    "                if self.market_metrics:\n",
    "                    pd.DataFrame(self.market_metrics).T.to_excel(writer, sheet_name=\"market_metrics\")\n",
    "            print(f\"ðŸ“ Exported to {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Export error: {e}\")\n",
    "\n",
    "    # --------------------------- Historical Load --------------------------- #\n",
    "\n",
    "    def _load_historical_data(self) -> None:\n",
    "        print(\"ðŸ“ˆ Loading historical price data...\")\n",
    "        for key, fname in self.cfg.historical_files.items():\n",
    "            fpath = self.cfg.data_folder / fname\n",
    "            print(f\"  â€¢ {key}: {fpath.name}\")\n",
    "            if not fpath.exists():\n",
    "                print(\"    â†³ âš ï¸ File not found, skipping.\")\n",
    "                continue\n",
    "            try:\n",
    "                df_raw = pd.read_excel(fpath, sheet_name=self.cfg.sheet, engine=self.cfg.excel_engine, header=None)\n",
    "                df_clean = (\n",
    "                    self._clean_jkm(df_raw) if \"jkm\" in key.lower()\n",
    "                    else self._clean_generic_price(df_raw, key)\n",
    "                )\n",
    "                if df_clean.empty:\n",
    "                    print(\"    â†³ âŒ No valid rows after cleaning.\")\n",
    "                else:\n",
    "                    self.historical_data[key] = df_clean\n",
    "                    print(f\"    â†³ âœ… {len(df_clean)} rows.\")\n",
    "            except Exception as e:\n",
    "                print(f\"    â†³ âŒ Error: {e}\")\n",
    "\n",
    "    # ---------------------------- Forward Load ----------------------------- #\n",
    "\n",
    "    def _load_forward_data(self) -> None:\n",
    "        print(\"ðŸ“ˆ Loading forward curve data...\")\n",
    "        for key, fname in self.cfg.forward_files.items():\n",
    "            fpath = self.cfg.data_folder / fname\n",
    "            print(f\"  â€¢ {key}: {fpath.name}\")\n",
    "            if not fpath.exists():\n",
    "                print(\"    â†³ âš ï¸ File not found, skipping.\")\n",
    "                continue\n",
    "            try:\n",
    "                df_raw = pd.read_excel(fpath, sheet_name=self.cfg.sheet, engine=self.cfg.excel_engine)\n",
    "                df = self._clean_forward(df_raw, key)\n",
    "                if df.empty:\n",
    "                    print(\"    â†³ âŒ No valid rows after cleaning.\")\n",
    "                else:\n",
    "                    self.forward_data[key] = df\n",
    "                    print(f\"    â†³ âœ… {len(df)} rows.\")\n",
    "            except Exception as e:\n",
    "                print(f\"    â†³ âŒ Error: {e}\")\n",
    "\n",
    "    # ---------------------------- Cleaners -------------------------------- #\n",
    "\n",
    "    def _clean_generic_price(self, df: pd.DataFrame, name: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Generic cleaner: tries to find a 2-column (date, price) table anywhere in the sheet.\n",
    "        \"\"\"\n",
    "        df2 = df.copy()\n",
    "        df2.replace(r\"^\\s*$\", np.nan, regex=True, inplace=True)\n",
    "        df2.dropna(how=\"all\", inplace=True)\n",
    "\n",
    "        # Heuristic: find first row that contains a \"date-ish\" value and then numeric values after it.\n",
    "        # Weâ€™ll scan nearby rows to infer headers if present.\n",
    "        # If the sheet already has tidy columns, this will still work.\n",
    "        candidates: List[Tuple[int, List[str]]] = []\n",
    "        for i in range(min(len(df2), 200)):  # limit scan\n",
    "            row = df2.iloc[i].tolist()\n",
    "            text_row = [self._clean_str(x) for x in row]\n",
    "            if any(k in \" \".join(text_row) for k in [\"date\", \"exchange date\", \"trade date\"]):\n",
    "                candidates.append((i, text_row))\n",
    "\n",
    "        # If we saw an explicit header, use it\n",
    "        header_row = candidates[0][0] if candidates else None\n",
    "        if header_row is not None:\n",
    "            data = df2.iloc[header_row + 1:].copy()\n",
    "            cols = [self._clean_str(x) or f\"col{j}\" for j, x in enumerate(df2.iloc[header_row].tolist())]\n",
    "            data.columns = cols\n",
    "        else:\n",
    "            # Fallback: assume first two non-empty columns are date/price\n",
    "            data = df2.copy()\n",
    "            data.columns = [f\"col{j}\" for j in range(data.shape[1])]\n",
    "\n",
    "        # Find likely date / price columns\n",
    "        dcol, pcol = self._infer_date_price_columns(data.columns)\n",
    "        if dcol not in data.columns or pcol not in data.columns:\n",
    "            # try again with simple first two columns\n",
    "            dcol, pcol = data.columns[:2]\n",
    "\n",
    "        out = data[[dcol, pcol]].rename(columns={dcol: \"date\", pcol: \"price\"}).copy()\n",
    "        out[\"date\"] = pd.to_datetime(out[\"date\"], errors=\"coerce\")\n",
    "        out[\"price\"] = pd.to_numeric(out[\"price\"], errors=\"coerce\")\n",
    "        out.dropna(subset=[\"date\", \"price\"], inplace=True)\n",
    "        out.sort_values(\"date\", inplace=True)\n",
    "        return self._add_returns_and_vol(out, name)\n",
    "\n",
    "    def _clean_jkm(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        JKM workbook cleaner: reliably finds the 'JKMc1 History' table and\n",
    "        uses its header row ('Exchange Date', 'Close', 'Net', '%Chg', 'Volume', 'OI').\n",
    "        \"\"\"\n",
    "        # 1) locate the \"JKMc1 History\" anchor row (any column)\n",
    "        anchor = self._find_row_containing(df, patterns=[r\"jkmc?1\\s+history\"], anywhere=True)\n",
    "        if anchor is None:\n",
    "            # Some files label it simply \"History\" â€” fallback to generic\n",
    "            return self._clean_generic_price(df, \"jkm_historical\")\n",
    "\n",
    "        # 2) find the actual header row within the next ~15 rows (search across all columns)\n",
    "        header = self._find_header_row(\n",
    "            df,\n",
    "            start=anchor,\n",
    "            window=20,\n",
    "            required_any=[\"exchange date\"],\n",
    "            required_all=[]\n",
    "        )\n",
    "        if header is None:\n",
    "            return self._clean_generic_price(df, \"jkm_historical\")\n",
    "\n",
    "        # 3) carve out the body until a blank row or a new section keyword\n",
    "        stop_keywords = [\"statistics\", \"vap\", \"summary\"]\n",
    "        data_start = header + 1\n",
    "        data_end = self._find_table_end(df, data_start, stop_keywords)\n",
    "\n",
    "        body = df.iloc[data_start:data_end].copy()\n",
    "        cols = [self._clean_str(x) or f\"col{j}\" for j, x in enumerate(df.iloc[header].tolist())]\n",
    "        body.columns = cols\n",
    "\n",
    "        # 4) choose columns: date = 'exchange date' (or similar), price = 'close'\n",
    "        dcol = self._pick_col(body.columns, [\"exchange date\", \"date\"])\n",
    "        pcol = self._pick_col(body.columns, [\"close\", \"settle\", \"price\"])\n",
    "        if dcol is None or pcol is None:\n",
    "            return self._clean_generic_price(df, \"jkm_historical\")\n",
    "\n",
    "        out = body[[dcol, pcol]].rename(columns={dcol: \"date\", pcol: \"price\"}).copy()\n",
    "        out[\"date\"] = pd.to_datetime(out[\"date\"], errors=\"coerce\")\n",
    "        out[\"price\"] = pd.to_numeric(out[\"price\"], errors=\"coerce\")\n",
    "        out.dropna(subset=[\"date\", \"price\"], inplace=True)\n",
    "        out.sort_values(\"date\", inplace=True)\n",
    "        return self._add_returns_and_vol(out, \"jkm_historical\")\n",
    "\n",
    "    def _clean_forward(self, df: pd.DataFrame, name: str) -> pd.DataFrame:\n",
    "        df2 = df.copy()\n",
    "        df2.replace(r\"^\\s*$\", np.nan, regex=True, inplace=True)\n",
    "        df2.dropna(how=\"all\", inplace=True)\n",
    "        # convert numeric columns where possible (leave tenor/date labels as-is)\n",
    "        for c in df2.columns[1:]:\n",
    "            df2[c] = pd.to_numeric(df2[c], errors=\"ignore\")\n",
    "        return df2\n",
    "\n",
    "    # --------------------------- Metrics ----------------------------------- #\n",
    "\n",
    "    def _add_returns_and_vol(self, df: pd.DataFrame, source_name: str) -> pd.DataFrame:\n",
    "        df = df.copy()\n",
    "        df.set_index(\"date\", inplace=True)\n",
    "        df[\"daily_return\"] = df[\"price\"].pct_change()\n",
    "        df[\"volatility_30d\"] = (\n",
    "            df[\"daily_return\"]\n",
    "            .rolling(self.cfg.boiloff_window_days)\n",
    "            .std()\n",
    "            * np.sqrt(self.cfg.annualization_trading_days)\n",
    "        )\n",
    "        df[\"source\"] = source_name\n",
    "        return df\n",
    "\n",
    "    def _calculate_market_metrics(self) -> Dict[str, Dict]:\n",
    "        metrics: Dict[str, Dict] = {}\n",
    "        for name, data in self.historical_data.items():\n",
    "            if data.empty or \"price\" not in data.columns:\n",
    "                continue\n",
    "            latest = float(data[\"price\"].iloc[-1])\n",
    "            base_idx = -self.cfg.boiloff_window_days if len(data) >= self.cfg.boiloff_window_days else 0\n",
    "            then = float(data[\"price\"].iloc[base_idx])\n",
    "            metrics[name] = {\n",
    "                \"current_price\": latest,\n",
    "                \"price_change_30d\": ((latest - then) / then) * 100 if then else np.nan,\n",
    "                \"volatility_30d\": float(data[\"volatility_30d\"].iloc[-1]) if \"volatility_30d\" in data.columns else np.nan,\n",
    "                \"price_52w_high\": float(data[\"price\"].max()),\n",
    "                \"price_52w_low\": float(data[\"price\"].min()),\n",
    "                \"data_points\": int(len(data)),\n",
    "                \"date_range\": f\"{data.index.min().date()} to {data.index.max().date()}\",\n",
    "            }\n",
    "        return metrics\n",
    "\n",
    "    # ------------------------- Helper routines ----------------------------- #\n",
    "\n",
    "    @staticmethod\n",
    "    def _clean_str(x) -> str:\n",
    "        if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "            return \"\"\n",
    "        return str(x).strip().replace(\"\\xa0\", \" \").lower()\n",
    "\n",
    "    def _find_row_containing(\n",
    "        self, df: pd.DataFrame, patterns: Iterable[str], anywhere: bool = False\n",
    "    ) -> Optional[int]:\n",
    "        \"\"\"Return the first row index where any regex pattern matches (in col0 or anywhere).\"\"\"\n",
    "        pats = [re.compile(p, flags=re.I) for p in patterns]\n",
    "        for i in range(len(df)):\n",
    "            row = df.iloc[i]\n",
    "            cells = row.tolist() if anywhere else [row.iloc[0]]\n",
    "            text = \" \".join(self._clean_str(c) for c in cells)\n",
    "            if any(p.search(text) for p in pats):\n",
    "                return i\n",
    "        return None\n",
    "\n",
    "    def _find_header_row(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        start: int,\n",
    "        window: int,\n",
    "        required_any: List[str],\n",
    "        required_all: List[str],\n",
    "    ) -> Optional[int]:\n",
    "        \"\"\"Search rows [start, start+window) for a header line containing tokens.\"\"\"\n",
    "        req_any = [self._clean_str(x) for x in required_any]\n",
    "        req_all = [self._clean_str(x) for x in required_all]\n",
    "        for i in range(start, min(start + window, len(df))):\n",
    "            row = df.iloc[i].tolist()\n",
    "            row_text = \" \".join(self._clean_str(x) for x in row)\n",
    "            if any(tok in row_text for tok in req_any) and all(tok in row_text for tok in req_all):\n",
    "                return i\n",
    "        return None\n",
    "\n",
    "    def _find_table_end(self, df: pd.DataFrame, start: int, stop_keywords: List[str]) -> int:\n",
    "        stops = [self._clean_str(k) for k in stop_keywords]\n",
    "        for i in range(start, len(df)):\n",
    "            row = df.iloc[i]\n",
    "            first = self._clean_str(row.iloc[0])\n",
    "            # stop on blank row or a keyword signaling a new section\n",
    "            if first == \"\" or any(k in first for k in stops):\n",
    "                return i\n",
    "        return len(df)\n",
    "\n",
    "    @staticmethod\n",
    "    def _infer_date_price_columns(columns: Iterable[str]) -> Tuple[str, str]:\n",
    "        cols = [str(c).lower() for c in columns]\n",
    "        # best guesses\n",
    "        d = next((c for c in columns if re.search(r\"date|exchange\", str(c), flags=re.I)), None)\n",
    "        p = next((c for c in columns if re.search(r\"close|price|settle|usd\", str(c), flags=re.I)), None)\n",
    "        # fallback\n",
    "        if d is None: d = list(columns)[0]\n",
    "        if p is None: p = list(columns)[1 if len(list(columns)) > 1 else 0]\n",
    "        return d, p\n",
    "\n",
    "    @staticmethod\n",
    "    def _pick_col(columns: Iterable[str], candidates: List[str]) -> Optional[str]:\n",
    "        low = {str(c).lower(): c for c in columns}\n",
    "        for want in candidates:\n",
    "            for k, original in low.items():\n",
    "                if want in k:\n",
    "                    return original\n",
    "        return None\n",
    "\n",
    "    # ----------------------------- Debugging ------------------------------- #\n",
    "\n",
    "    def debug_data_structure(self, filename: str) -> pd.DataFrame:\n",
    "        \"\"\"Print a quick structure summary for a raw Excel file (first sheet).\"\"\"\n",
    "        path = self.cfg.data_folder / filename\n",
    "        print(f\"ðŸ” Debug: {path}\")\n",
    "        try:\n",
    "            df = pd.read_excel(path, sheet_name=self.cfg.sheet, engine=self.cfg.excel_engine, header=None)\n",
    "        except Exception as e:\n",
    "            print(\"âŒ Read error:\", e)\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        print(\"shape:\", df.shape)\n",
    "        print(\"top 15 rows:\")\n",
    "        with pd.option_context(\"display.max_columns\", None, \"display.width\", 200):\n",
    "            print(df.head(15))\n",
    "        anchor = self._find_row_containing(df, [r\"jkmc?1\\s+history\"], anywhere=True)\n",
    "        print(\"JKMc1 History anchor:\", anchor)\n",
    "        if anchor is not None:\n",
    "            header = self._find_header_row(df, anchor, window=20, required_any=[\"exchange date\"], required_all=[])\n",
    "            print(\"Header row guess:\", header)\n",
    "            if header is not None:\n",
    "                print(\"Header cells:\", df.iloc[header].tolist())\n",
    "        return df\n",
    "\n",
    "\n",
    "# --------------------------- Example usage --------------------------------- #\n",
    "if __name__ == \"__main__\":\n",
    "    loader = LNGDataLoader()\n",
    "    hist = loader.load_all_data()\n",
    "\n",
    "    if loader.market_metrics:\n",
    "        print(\"\\nðŸ“Š Market Data Summary\")\n",
    "        print(\"-\" * 70)\n",
    "        for name, m in loader.market_metrics.items():\n",
    "            print(f\"\\n{name}:\")\n",
    "            for k, v in m.items():\n",
    "                if isinstance(v, float):\n",
    "                    print(f\"  {k}: {v:.4f}\")\n",
    "                else:\n",
    "                    print(f\"  {k}: {v}\")\n",
    "\n",
    "    current = loader.get_current_prices_for_optimization()\n",
    "    print(\"\\nðŸ’° Current Prices for Optimisation mapping\")\n",
    "    for code, val in current.items():\n",
    "        print(f\"  {code}: {val:.2f}\")\n",
    "\n",
    "    # Uncomment to export\n",
    "    # loader.export_data(\"lng_market_data.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39cd8acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2/2\u001b[0m [openpyxl]\n",
      "\u001b[1A\u001b[2KSuccessfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e347d111",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
